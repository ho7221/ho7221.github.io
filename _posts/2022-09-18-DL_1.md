---
title: "[DL] Lec 1. Image Classification"
category: COSE474
excerpt: "Lecture 1. Image Classification"
toc: true
toc_sticky: true
toc_label: "Table of Contents"
toc_icon: "bars"
---

# non-parametric Classifier
이때 parameter가 필요없이 K만 있으면 되기때문에 non-parametric하다고 한다.

## K-Nearest Neighbor
Dataset에서 원하는 data point를 정의하기 위해 근접하는 K개의 점의 분류로 해당 data point를 정의하는 것.  

# parametric Classifier
선형회귀를 예로 y=Ax+b 들때 A와 b라는 parameter(가중치)가 필요하다. 이런 classifier를 parametric classifier라고 한다.
- Neural Networks
- Naive Bayes
...

# 그 중간 어딘가...
- SVM

# Linear Classifier
32x32x3 크기의 image를 10개의 class로 분류하는 예시를 들어보자. 
f(x;W,b) 에서 x를 image, W를 parameter(가중치)로 input을 받는 classifier f를 정의한다.
이때 f(x;W,b)=Wx+b에서 
- input: [3072x1] vector
- output: [10x1] vector
- Weight: [10x3072] vector 
- Bias: [10x1] vector
이며 parameter는 W,b가 된다.

관점에 따라 세가지로 나누는데
## Algebric Viewpoint
f(x,W)=Wx

## Visual Viewpoint
## Geometric Viewpoint
image들의 공간을 나누는 hyperplane.


